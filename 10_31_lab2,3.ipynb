{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-02 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Hypothesis\n",
    "\n",
    "선형회귀는 학습데이터와 가장 잘 맞는 하나의 직선을 만드는 것이므로 $y=Wx+b$ 라는 식을 통해 Hypothesis식을 나타낼 수 있다.\n",
    "\n",
    "(x는 input, y는 output을 뜻한다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch와 torch에서 optimizer가 내장되어있는 optim을 부른다.\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data와 label을 불러온다.\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "# Weight와 Bias를 초기화 하고 requires_grad = True로 해준다.\n",
    "# 학습을 할 것이라는 뜻\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "# hypothesis를 이렇게 쉽게 표현할 수 있다.\n",
    "hypothesis = x_train * W + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss\n",
    "\n",
    "Linear regression에서는 loss값을 Mean Squared Error(MSE)를 사용하여 계산하게 되며,\n",
    "MSE는 단순히 hypothesis와 real target값의 차이의 제곱의 평균이다. \n",
    "\n",
    "식으로 보면 $$Cost(W,b) = \\frac{1}{m}\\sum_{i=1}^{m}\\left( H(x^{(i)})-y^{(i)} \\right)^{2}$$ 이러하다. $m$은 data의 갯수, $H(x)$는 위의 hypothesis 값을 의미한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent(SGD)\n",
    "\n",
    "이후 Stochastic Gradient Descent(SGD)를 이용하여 최적화를 해줍니다.\n",
    "Gradient Descent의 cost가 최소값을 가지게 하는 $W$와 $b$를 찾는 것이 목적이다. \n",
    "\n",
    "그렇기 때문에 미분을 통해 최소값을 향해 움직이게 된다. 식은 다음과 같다. $$ cost(W) = \\frac{1}{m}\\sum_{i=1}^{m}\\left(Wx^{(i)}-y^{(i)}\\right)^2 $$\n",
    "$$ \\nabla W= \\frac{\\partial cost}{\\partial W} = \\frac{2}{m}\\sum_{i=1}^{m}\\left(Wx^{(i)}-y^{(i)}\\right)x^{(i)}$$\n",
    "$$ W : = W-\\alpha\\nabla W$$ 여기서 $\\alpha$는 learning rate를 뜻한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr = 0.01)\n",
    "optimizer.zero_grad() ## gradient를 0 으로 초기화\n",
    "cost.backward() ## gradient 계산\n",
    "optimizer.step() ## gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이를 한번에 한 코드 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000, W: 1.745, Cost:0.048403\n",
      "Epoch  200/1000, W: 1.800, Cost:0.029910\n",
      "Epoch  300/1000, W: 1.842, Cost:0.018483\n",
      "Epoch  400/1000, W: 1.876, Cost:0.011421\n",
      "Epoch  500/1000, W: 1.903, Cost:0.007058\n",
      "Epoch  600/1000, W: 1.923, Cost:0.004361\n",
      "Epoch  700/1000, W: 1.940, Cost:0.002695\n",
      "Epoch  800/1000, W: 1.953, Cost:0.001665\n",
      "Epoch  900/1000, W: 1.963, Cost:0.001029\n",
      "Epoch 1000/1000, W: 1.971, Cost:0.000636\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(1,epochs+1):\n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch %100 ==0:\n",
    "        print('Epoch {:4d}/{}, W: {:.3f}, Cost:{:.6f}'.format(\n",
    "        epoch,epochs,W.item(),cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
